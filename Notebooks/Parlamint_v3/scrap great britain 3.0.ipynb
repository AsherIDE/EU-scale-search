{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93cd3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e19a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir\n",
    "merged_csv_dir = r\"D:\\Debate_a_Base\\Data\\Parlamint_3.0\\Csv_set\\GB\"\n",
    "xml_dir = r\"D:\\Debate_a_Base\\Data\\Parlamint_3.0\\Originele_taal\\original_extract\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df184e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vraagt alle files uit de folder op\n",
    "def get_xml_files(country):\n",
    "    os.chdir(xml_dir)\n",
    "    \n",
    "    country_return_list = []\n",
    "\n",
    "    paths_dict = {}\n",
    "\n",
    "    # ga door alle inhoud van de landfolder heen\n",
    "    for root, dirs, files in os.walk(country):\n",
    "        file_data = []\n",
    "\n",
    "        # loop door files van een folder\n",
    "        for file in files:\n",
    "\n",
    "            #filter alleen de xml files\n",
    "            if \".xml\" in file and not \"~\" in file:\n",
    "                file_data.append(file)\n",
    "\n",
    "        # filter onzin uit de dict voor makkelijkere processing later\n",
    "        if not \"Schema\" in root:\n",
    "            paths_dict[root] = file_data\n",
    "        \n",
    "    return paths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce9778e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xml_content_dict(path):\n",
    "    os.chdir(xml_dir)\n",
    "    \n",
    "    content_dict = {}\n",
    "    \n",
    "    # lees het bestand\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        # read each line in the file, readlines() returns a list of lines\n",
    "        content = file.readlines()\n",
    "        # combine the lines in the list into a string\n",
    "        content = \"\".join(content)\n",
    "        bs_content = bs(content, \"lxml\")\n",
    "        \n",
    "        # ga door alle segmenten info heen\n",
    "        userlines = bs_content.find_all(\"u\")\n",
    "        for line in userlines:\n",
    "    \n",
    "            # definieer segment\n",
    "            seg = line.get(\"xml:id\")\n",
    "\n",
    "            # definieer content (deze nieuwe manier negeert notes)\n",
    "            mergable_lines = line.find_all(\"seg\")\n",
    "            cnt = \"\"\n",
    "            for mergable_line in mergable_lines:\n",
    "\n",
    "                cnt += f\"{mergable_line.text} \"\n",
    "                \n",
    "            content_dict[seg] = cnt\n",
    "    \n",
    "    return content_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c23106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maak een csv waar segments zijn gemerged per file\n",
    "def create_userline_csv(file, content):\n",
    "    os.chdir(merged_csv_dir)\n",
    "    file = file.replace(\".xml\", \".csv\")\n",
    "    \n",
    "    with open(file, 'w', newline='', encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"key\", \"value\"])\n",
    "        \n",
    "        for k, v in content.items():\n",
    "            \n",
    "            w.writerow([k, v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12abfff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zet GB dataset om naar userline translation tier files\n",
    "def scrap_gb(country):\n",
    "    files = get_xml_files(country)\n",
    "    \n",
    "    # split hoofdfolder van mogelijke subfolders van jaren\n",
    "    rootfolder = (k := next(iter(files)), files.pop(k))\n",
    "    \n",
    "    # ga door jaarfolders\n",
    "    for year in files.keys():\n",
    "        \n",
    "        # ga elke file langs\n",
    "        for file in files[year]:\n",
    "            path = os.path.join(year, file)\n",
    "            \n",
    "            file_content_dict = get_xml_content_dict(path)\n",
    "            \n",
    "            create_userline_csv(file, file_content_dict)\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e36bd29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asher\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "scrap_this = 'ParlaMint-GB.TEI'\n",
    "\n",
    "print(scrap_gb(scrap_this))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
