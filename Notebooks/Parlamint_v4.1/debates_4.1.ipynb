{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52843471",
   "metadata": {},
   "source": [
    "# Debate a base\n",
    "#### Update script (Parlamint 4.1)\n",
    "\n",
    "\n",
    "### Functions\n",
    "- Uploads all Parlamint data to ElasticSearch for the `debates` page\n",
    "\n",
    "### Don't forget to:\n",
    "- Make sure that nothing else inside of the `data/original/EU` and `data/original/EN` folders besides what was mentioned in the step-by-step guide\n",
    "- Fill in `es_host`, `es_user` and `es_password` so you can connect with your ElasticSearch instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c7fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in credentials over here!\n",
    "es_host = \"https://localhost:9200\"\n",
    "es_user = \"CHANGEME\"\n",
    "es_password = \"CHANGEME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57fa7b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local paths according to the step-by-step guide\n",
    "original_set = \"../data/original/EU\"\n",
    "translated_set = \"../data/original/EN\"\n",
    "\n",
    "# Setup elastic host connection\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "es = Elasticsearch(\n",
    "    hosts=[\n",
    "        es_host\n",
    "    ],\n",
    "    http_auth=(es_user, es_password),\n",
    "#     use_ssl=True,\n",
    "    verify_certs=False,\n",
    "#     ca_certs=\"./ca.crt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdcbd81",
   "metadata": {},
   "source": [
    "### Delete previous version of debates index on your ElasticSearch instance\n",
    "- Do this in case your `search` index for the debates page is not empty\n",
    "- Delete the \"search\" index manually or execute the following command\n",
    "- Don't forget to make it a comment again after executing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d8aa2578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# es.indices.delete(index='search')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c380597",
   "metadata": {},
   "source": [
    "### Execution\n",
    "- Click \"Kernel\" > \"Restart & run all\"\n",
    "- At the bottom, below the last MarkDown cell, it should be printing information about files being uploaded to ElasticSearch\n",
    "- THIS TAKES A VERY LONG TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e1c5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8052cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from .tgz\n",
    "original_set_extract = \"../EU\"\n",
    "translated_set_extract = \"../EN\"\n",
    "\n",
    "# Removes obsolete extracted files (must be updated to work again)\n",
    "# def clean_folder(path):\n",
    "#     os.chdir(path)\n",
    "    \n",
    "#     for folder in os.listdir():\n",
    "#         if \".TEI\" not in folder:\n",
    "#             shutil.rmtree(os.path.join(path, folder))\n",
    "\n",
    "# # Original data\n",
    "# os.chdir(original_set)\n",
    "\n",
    "# if \"EU\" not in os.listdir(\"../../preprocessed\"):\n",
    "#     for folder in os.listdir():\n",
    "#         if folder != \"ParlaMint-4.1.tar.gz\":\n",
    "#             folder_extract = tarfile.open(folder)\n",
    "            \n",
    "#             folder_extract.extractall(\"../../preprocessed/EU\")\n",
    "#             folder_extract.close()\n",
    "#     print(\"[Info]: EU created\")\n",
    "# else:\n",
    "#     print(\"[Info]: EU already exists\")\n",
    "\n",
    "# clean_folder(original_set_extract)\n",
    "            \n",
    "# # Translated data\n",
    "# os.chdir(translated_set)\n",
    "\n",
    "# if \"EN\" not in os.listdir(\"../../preprocessed\"):\n",
    "#     for folder in os.listdir():\n",
    "#         if folder != \"ParlaMint-4.1-en.tar.gz\":\n",
    "#             os.chdir(translated_set)\n",
    "            \n",
    "#             folder_extract = tarfile.open(folder)\n",
    "            \n",
    "#             folder_extract.extractall(\"../../preprocessed/EN\")\n",
    "#             folder_extract.close()\n",
    "            \n",
    "#             clean_folder(translated_set_extract)\n",
    "#     print(\"[Info]: EN created\")\n",
    "# else:\n",
    "#     print(\"[Info]: EN already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1354b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the file structure\n",
    "def get_xml_files(country_selection):\n",
    "    country_return_list = []\n",
    "\n",
    "    # loop door alle folders die hierboven zijn geprint\n",
    "    for country in os.listdir():\n",
    "\n",
    "        # filter op specifiek land (IN BOX 2)\n",
    "        if country in country_selection:\n",
    "            paths_dict = {}\n",
    "\n",
    "            # ga door alle inhoud van de landfolder heen\n",
    "            for root, dirs, files in os.walk(country):\n",
    "                file_data = []\n",
    "                \n",
    "                # loop door files van een folder\n",
    "                for file in files:\n",
    "\n",
    "                    #filter alleen de xml files\n",
    "                    if \".xml\" in file and not \"~\" in file:\n",
    "                        file_data.append(file)\n",
    "\n",
    "                # filter onzin uit de dict voor makkelijkere processing later\n",
    "                if not \"Schema\" in root:\n",
    "                    paths_dict[root] = file_data\n",
    "\n",
    "            country_return_list.append(paths_dict)\n",
    "        \n",
    "    return country_return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42efda19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functie testruimte\n",
    "# selected_countries = [\"ParlaMint-NL.TEI\"]\n",
    "\n",
    "# answer = get_xml_files(selected_countries)\n",
    "\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "effd8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve person info\n",
    "@dataclass\n",
    "class Person:\n",
    "    p_id: str\n",
    "    name: str\n",
    "    party: str\n",
    "    sex: str\n",
    "\n",
    "# haalt nodige informatie uit het overkoepelende bestand dat per land bestaat\n",
    "# NOTE: Deze functie gaat later overige nodige info over personen en partijen ook meegeven\n",
    "# goede characteromvorming schrijven zodat puntjes op speciale letters niet vervormen\n",
    "def extract_info_xml(root, org_file, person_file):\n",
    "    path = os.path.join(root, org_file)\n",
    "    person_dict, party_dict = {}, {}\n",
    "    \n",
    "    # lees het party bestand\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        # read each line in the file, readlines() returns a list of lines\n",
    "        content = file.readlines()\n",
    "        # combine the lines in the list into a string\n",
    "        content = \"\".join(content)\n",
    "        \n",
    "        bs_content = bs(content, \"html.parser\")\n",
    "    \n",
    "        # maakt dict met --> partij id (key) : partij naam (value)\n",
    "        for party in bs_content.find_all(\"org\"):\n",
    "            \n",
    "            # definieer partij afkorting en volledige naam\n",
    "            part_y_1 = party.find_all(\"orgname\")[-1].text #party.get(\"xml:id\").split(\".\")[-1]\n",
    "            part_y_2 = party.find_all(\"orgname\")\n",
    "            \n",
    "            # kies met voorkeur de engelse variant van party\n",
    "            for orgname in part_y_2:\n",
    "                if orgname.get(\"full\") == \"yes\" and orgname.get(\"xml:lang\") == \"en\":\n",
    "                    part_y_2 = orgname.text\n",
    "                    break\n",
    "            \n",
    "            # kies anders de full variant\n",
    "            else:\n",
    "                \n",
    "                for orgname in part_y_2:\n",
    "                    \n",
    "                    if orgname.get(\"full\") == \"yes\":\n",
    "                        part_y_2 = orgname.text\n",
    "                        break\n",
    "                \n",
    "                # pak de eerste partijnaam als er geen betere zijn\n",
    "                else:\n",
    "                    part_y_2 = part_y_2[0].text\n",
    "            \n",
    "            # kijk welke langer is en zet die achteraan\n",
    "            if len(part_y_1) > len(part_y_2):\n",
    "                party_dict[party.get(\"xml:id\")] = f\"{part_y_2} ({part_y_1})\" \n",
    "            else:\n",
    "                party_dict[party.get(\"xml:id\")] = f\"{part_y_1} ({part_y_2})\"\n",
    "    \n",
    "    # lees het person bestand\n",
    "    path = os.path.join(root, person_file)\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        # read each line in the file, readlines() returns a list of lines\n",
    "        content = file.readlines()\n",
    "        # combine the lines in the list into a string\n",
    "        content = \"\".join(content)\n",
    "        \n",
    "        bs_content = bs(content, \"html.parser\")\n",
    "    \n",
    "    # krijg de juiste achternaam\n",
    "    def get_surname(person):\n",
    "        # pak de 2e achternaam als die er is (find_all -1 kan niet omdat er in dat geval ook 4 kunnen zijn)\n",
    "        if len(person.find_all('surname')) == 1:\n",
    "            return person.find('surname').text\n",
    "        else:\n",
    "            return person.find_all('surname')[1].text\n",
    "        \n",
    "    # vind de juiste partij\n",
    "    def get_affiliation(person):\n",
    "        \n",
    "        # ga van nieuw-oud door affiliations heen\n",
    "        for affiliation in reversed(person.find_all(\"affiliation\")):\n",
    "    \n",
    "            # return party als die ook in party_dict staat\n",
    "            if affiliation.get('ref') is not None and affiliation.get('ref').strip(\"#\") in party_dict:\n",
    "                \n",
    "                return party_dict[affiliation.get('ref').strip(\"#\")]\n",
    "    \n",
    "    # ga door alle user info heen\n",
    "    persons = bs_content.find_all(\"person\")\n",
    "    for person in persons:\n",
    "        \n",
    "        # NOTE: person.find_all('surname')[-1] voor laatste surname\n",
    "        if person.find(\"affiliation\") != None:\n",
    "            \n",
    "            pers = Person(person.get(\"xml:id\"), \n",
    "                          (person.find('forename').text + \" \" + get_surname(person)),\n",
    "                          get_affiliation(person),\n",
    "                          (person.find(\"sex\").get('value') if person.find(\"sex\") is not None else \"None\"))\n",
    "            \n",
    "            person_dict[person.get(\"xml:id\")] = pers\n",
    "        \n",
    "        # dit zorgt er voor dat mensen zonder partij als None worden gezet\n",
    "        elif person.find('forename') != None:\n",
    "            \n",
    "            pers = Person(person.get(\"xml:id\"), \n",
    "                          (person.find('forename').text + \" \" + get_surname(person)),\n",
    "                          \"None\",\n",
    "                          (person.find(\"sex\").get('value') if person.find(\"sex\") is not None else \"None\"))\n",
    "            \n",
    "            person_dict[person.get(\"xml:id\")] = pers\n",
    "                \n",
    "        # neem xml:id als naam\n",
    "        else:\n",
    "\n",
    "            pers = Person(person.get(\"xml:id\"), \n",
    "                          person.get(\"xml:id\"),\n",
    "                          \"None\",\n",
    "                          \"None\")\n",
    "            \n",
    "            person_dict[person.get(\"xml:id\")] = pers\n",
    "            \n",
    "    return person_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c132869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functie testruimte\n",
    "# root, file_org, file_person = \"ParlaMint-NL.TEI\", \"ParlaMint-NL-listOrg.xml\", \"ParlaMint-NL-listPerson.xml\"\n",
    "# root, file_org, file_person = \"ParlaMint-TR.TEI\", \"ParlaMint-TR-listOrg.xml\", \"ParlaMint-TR-listPerson.xml\"\n",
    "\n",
    "# test_person_dict = extract_info_xml(root, file_org, file_person)\n",
    "\n",
    "# print(test_person_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e54116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the date of a file\n",
    "def extract_file_date(file_name):\n",
    "    year_month_day = re.search(r\"\\d{4}-\\d{2}-\\d{2}\", file_name)\n",
    "    year, month, day = year_month_day[0].split(\"-\")\n",
    "    \n",
    "    return year, month, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e1ea65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# haal de nodige data uit de xml en zet het in een list dict\n",
    "def extract_debate_xml(root, file, country_info_dict, cty, translation_df=None, count=0, index=\"search\"):\n",
    "    # os.chdir(original_set)\n",
    "    \n",
    "    path = os.path.join(root, file)\n",
    "    content_dict_list = []\n",
    "    file_dummy = file\n",
    "    \n",
    "    # lees het bestand\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        # read each line in the file, readlines() returns a list of lines\n",
    "        content = file.readlines()\n",
    "        # combine the lines in the list into a string\n",
    "        content = \"\".join(content)\n",
    "        bs_content = bs(content, \"html.parser\")\n",
    "    \n",
    "    # stel datum vast\n",
    "    year, month, day = extract_file_date(file.name)\n",
    "        \n",
    "    # ga door alle segmenten info heen\n",
    "    userlines = bs_content.find_all(\"u\")\n",
    "    for line in userlines:\n",
    "        \n",
    "        content_dict, es_content_dict = {}, {}\n",
    "        \n",
    "        # prs[0] = naam, prs[1] = partij, prs[2] = gender\n",
    "        prs = None\n",
    "        \n",
    "        # definieer segment\n",
    "        seg = line.get(\"xml:id\")\n",
    "\n",
    "        # definieer content (deze nieuwe manier negeert notes)\n",
    "        mergable_lines = line.find_all(\"seg\")\n",
    "        cnt = \"\"\n",
    "        for mergable_line in mergable_lines:\n",
    "            \n",
    "            cnt += f\"{mergable_line.text} \"\n",
    "            \n",
    "        cnt_s = unidecode(cnt)\n",
    "        \n",
    "        # kijk of er gegevens van de spreker zijn\n",
    "        if line.get(\"who\") != None:\n",
    "            prs = country_info_dict[line.get(\"who\").replace('#', '')]\n",
    "            \n",
    "            content_dict[\"person\"] = prs.name\n",
    "            content_dict[\"person_simplified\"] = unidecode(prs.name)\n",
    "            content_dict[\"party\"] = prs.party\n",
    "            content_dict[\"gender\"] = prs.sex\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            content_dict[\"person\"] = \"None\"\n",
    "            content_dict[\"person_simplified\"] = \"None\"\n",
    "            content_dict[\"party\"] = \"None\"\n",
    "            content_dict[\"gender\"] = \"None\"\n",
    "        \n",
    "        content_dict[\"file\"] = file_dummy\n",
    "        content_dict[\"segment\"] = seg\n",
    "        content_dict[\"year\"] = year\n",
    "        content_dict[\"month\"] = month\n",
    "        content_dict[\"day\"] = day\n",
    "        content_dict[\"position\"] = line.get(\"ana\")\n",
    "        content_dict[\"country\"] = cty\n",
    "        content_dict[\"content\"] = cnt\n",
    "        content_dict[\"content_simplified\"] = cnt_s.replace(\"\\'\", \"\")\n",
    "        \n",
    "        # voeg de translated line toe als die er is\n",
    "        if translation_df is not None and seg in translation_df.keys():\n",
    "            \n",
    "            translated_line = translation_df[seg]\n",
    "            \n",
    "            # kijk of de userline bestaat\n",
    "            if len(translated_line) != 0:\n",
    "            \n",
    "                content_dict[\"content_translated\"] = translated_line\n",
    "            \n",
    "            # userline bevat geen gesproken teksts\n",
    "            elif len(cnt) == 1:\n",
    "                \n",
    "                continue\n",
    "            \n",
    "            # wel gesproken teksts maar niet opgepakt door translater\n",
    "            else:\n",
    "                \n",
    "                content_dict[\"content_translated\"] = \"None\"\n",
    "                print(f\"[Missing translation]: {seg}\")\n",
    "        \n",
    "        # sla engels ook op zodat er op de site geen exception nodig is\n",
    "        elif cty == \"GB\":\n",
    "            content_dict[\"content_translated\"] = cnt\n",
    "        \n",
    "        # voeg nodige info toe aan elke xml_content_dict line voor bulk uploads\n",
    "        count += 1\n",
    "        \n",
    "        es_content_dict[\"_index\"] = index\n",
    "        es_content_dict[\"_id\"] = count\n",
    "        es_content_dict[\"_source\"] = content_dict\n",
    "    \n",
    "        # add the line to the list of lines\n",
    "        content_dict_list.append(es_content_dict)\n",
    "    \n",
    "    return content_dict_list, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e0e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # functie testruimte\n",
    "# root, file = os.path.join(original_set_extract, \"ParlaMint-BE.TEI\\\\2019\"), \"ParlaMint-BE_2019-01-16-54-commissie-ic1017x.xml\"\n",
    "# country_info_dict = extract_info_xml(\"ParlaMint-BE.TEI\", \"ParlaMint-BE-listOrg.xml\", \"ParlaMint-BE-listPerson.xml\")\n",
    "# # test_translated_df = get_translated_csv(\"BE\", file.split(\".xml\")[0] + \".csv\")\n",
    "\n",
    "# # TODO: Check of bij sommige COUNTRY\\\\JAARTAL staat ipv COUNTRY\n",
    "# country = root.replace(\"ParlaMint-\", \"\").replace(\".TEI\", \"\")\n",
    "# test_json = extract_debate_xml(root, file, country_info_dict, country)#, extract_translated_csv(country))\n",
    "\n",
    "# print(test_json[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "856cd415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vraag een dict met k (userline) v (sentence)\n",
    "def get_translated_dict(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        # read each line in the file, readlines() returns a list of lines\n",
    "        content = file.readlines()\n",
    "        # combine the lines in the list into a string\n",
    "        content = \"\".join(content)\n",
    "        bs_content = bs(content, \"html.parser\")\n",
    "\n",
    "    # ga door alle segmenten info heen\n",
    "    userlines = bs_content.find_all(\"u\")\n",
    "    segments = dict()\n",
    "    for line in userlines:\n",
    "        seg = line.get(\"xml:id\")\n",
    "        \n",
    "        # combineer de woorden tot een zin\n",
    "        combined_line = \"\"\n",
    "        for part_of_line in line.find_all(\"seg\"):\n",
    "            combined_line += part_of_line.text\n",
    "            combined_line = combined_line.replace(\"\\n\\n\", \" \").replace(\"\\n\", \" \").replace(\"  \", \" \")\n",
    "        \n",
    "        # zet de interpunctie goed\n",
    "        start_index = 0\n",
    "        punctuated_line = \"\"\n",
    "        for dot in re.finditer(\"\\.|,|\\?|\\!|\\)|;\", combined_line):\n",
    "            index = dot.start()\n",
    "\n",
    "            if combined_line[index - 1] == \" \":\n",
    "                punctuated_line += combined_line[start_index:(index - 1)] + combined_line[index]\n",
    "\n",
    "                start_index = (index + 1)\n",
    "        \n",
    "        # voorkom dat zinnen zonder interpunctie missing gaan\n",
    "        if punctuated_line == \"\":\n",
    "            punctuated_line = combined_line\n",
    "\n",
    "        # haal de spatie op het begin weg\n",
    "        if len(punctuated_line) > 0 and punctuated_line[0] == \" \":\n",
    "            punctuated_line = punctuated_line[1:]\n",
    "            \n",
    "        # sla de zin op met seg als key\n",
    "        segments[seg] = punctuated_line.replace(\"  \", \" \")\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f453e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functie testruimte\n",
    "# translate_path_test = r\"C:\\Users\\Asher\\Documents\\School\\_Scriptie\\Data\\Parlamint_3.0\\Overkoepelende_taal\\translated_extract\\ParlaMint-NL-en.TEI.ana\\2014\\ParlaMint-NL-en_2014-04-16-tweedekamer-2.ana.xml\"\n",
    "# translate_path_test = r\"C:\\Users\\Asher\\Documents\\School\\_Scriptie\\Data\\Parlamint_3.0\\Overkoepelende_taal\\translated_extract\\ParlaMint-BA-en.TEI.ana\\2009\\ParlaMint-BA-en_2009-09-16-0.ana.xml\"\n",
    "# translate_path_test = r\"C:\\Users\\Asher\\Documents\\School\\_Scriptie\\Data\\Parlamint_3.0\\Overkoepelende_taal\\translated_extract\\ParlaMint-BG-en.TEI.ana\\2014\\ParlaMint-BG-en_2014-11-05.ana.xml\"\n",
    "\n",
    "# for k, v in get_translated_dict(translate_path_test).items():\n",
    "#     print(k, \"\\n<\" + v + \">\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1d74aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload xml files\n",
    "def upload_xmls(selected_countries, cnt=0):\n",
    "    \n",
    "    # vraag alle xml files op van de gegeven land(en)\n",
    "    countries = get_xml_files(selected_countries)\n",
    "    \n",
    "    # loop door elk land heen\n",
    "    for country in countries:\n",
    "        \n",
    "        # split hoofdfolder van mogelijke subfolders van jaren\n",
    "        rootfolder = (k := next(iter(country)), country.pop(k))\n",
    "        for misleading_item in rootfolder[1]:\n",
    "            if \"listOrg\" in misleading_item:\n",
    "                organizations = misleading_item # normaal werkte dit ook rootfolder[1][0]\n",
    "            elif \"listPerson\" in misleading_item:\n",
    "                persons = misleading_item # rootfolder[1][1]\n",
    "        \n",
    "        # verzamel person info\n",
    "        country_info = extract_info_xml(rootfolder[0], organizations, persons)\n",
    "        \n",
    "        # country label (bv: GB of NL of BE)\n",
    "        cty = rootfolder[0].replace(\"ParlaMint-\", \"\").replace(\".TEI\", \"\")\n",
    "        translated_folder = [translated_folder for translated_folder in os.listdir(translated_set_extract) if cty in translated_folder]\n",
    "        \n",
    "        for year_folder in country:\n",
    "\n",
    "            for file in country[year_folder]:\n",
    "\n",
    "                # vraag de vertaalde bijbehorende file op (krijgt None als die er niet is)\n",
    "                # TODO: mogelijk betere check maken die ook kijkt of de file bestaat (ipv alleen folder)\n",
    "                if len(translated_folder) > 0:\n",
    "                    \n",
    "                    # ES is not rightfully selected between ES-CT and ES-GA so we handle it manually\n",
    "                    if not cty == \"ES\":\n",
    "                        path = os.path.join(*[translated_set_extract, translated_folder[0], year_folder.split('\\\\')[1], file.replace(\".xml\", \".ana.xml\").replace(\"_\", \"-en_\")])\n",
    "                    else:\n",
    "                        path = os.path.join(*[translated_set_extract, translated_folder[1], year_folder.split('\\\\')[1], file.replace(\".xml\", \".ana.xml\").replace(\"_\", \"-en_\")])\n",
    "                    translated_dict = get_translated_dict(path)\n",
    "                    \n",
    "                else:\n",
    "                    translated_dict = None\n",
    "\n",
    "                # verkrijg een verwerkt xml debat file en update counter\n",
    "                processed_xml, cnt = extract_debate_xml(year_folder, file, country_info, cty, translated_dict, cnt)\n",
    "\n",
    "                # testing area \n",
    "#                 print(\"\\n\", processed_xml[0], \"\\n\\n\")\n",
    "#                 break\n",
    "#             break\n",
    "                print(f\"[Uploaded]: {file} (id: {cnt})\")\n",
    "                helpers.bulk(es, processed_xml)\n",
    "\n",
    "        print(\"---------------------------------------------------------------\\n\\n\")\n",
    "        print(cty + \" is uploaded to elastic\\n\\n\")\n",
    "        print(\"---------------------------------------------------------------\\n\\n\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b6cd8b",
   "metadata": {},
   "source": [
    "### Everything is according to plan if the cell below shows print statements of files being uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7c8d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# os.listdir(\"../data/original/EU\")\n",
    "\n",
    "selected_countries = ['ParlaMint-AT.TEI',\n",
    "                    'ParlaMint-BA.TEI',\n",
    "                    'ParlaMint-BE.TEI',\n",
    "                    'ParlaMint-BG.TEI',\n",
    "                    'ParlaMint-CZ.TEI',\n",
    "                    'ParlaMint-DK.TEI',\n",
    "                    'ParlaMint-EE.TEI',\n",
    "                    'ParlaMint-ES-CT.TEI',\n",
    "                    'ParlaMint-ES-GA.TEI',\n",
    "                    'ParlaMint-ES-PV.TEI',\n",
    "                    'ParlaMint-ES.TEI',\n",
    "                    'ParlaMint-FI.TEI',\n",
    "                    'ParlaMint-FR.TEI',\n",
    "                    'ParlaMint-GB.TEI',\n",
    "                    'ParlaMint-GR.TEI',\n",
    "                    'ParlaMint-HR.TEI',\n",
    "                    'ParlaMint-HU.TEI',\n",
    "                    'ParlaMint-IS.TEI',\n",
    "                    'ParlaMint-IT.TEI',\n",
    "                    'ParlaMint-LV.TEI',\n",
    "                    'ParlaMint-NL.TEI',\n",
    "                    'ParlaMint-NO.TEI',\n",
    "                    'ParlaMint-PL.TEI',\n",
    "                    'ParlaMint-PT.TEI',\n",
    "                    'ParlaMint-RS.TEI',\n",
    "                    'ParlaMint-SE.TEI',\n",
    "                    'ParlaMint-SI.TEI',\n",
    "                    'ParlaMint-TR.TEI',\n",
    "                    'ParlaMint-UA.TEI']\n",
    "\n",
    "\n",
    "# NOTE: If this process gets interrupted, copy the id for the \"cnt\" variable from the last .xml file from the last country that was uploaded completely. Also remove all completed countries from list above\n",
    "start_time = time.time()\n",
    "upload_xmls(selected_countries, cnt=0)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
