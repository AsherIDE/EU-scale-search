{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246010f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import plotly.express as px\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir\n",
    "translated_csv_dir = r\"C:\\Users\\Asher\\Documents\\School\\_Scriptie\\Data\\Data_Userlines_CSV\"\n",
    "ngram_csv_dir = r\"C:\\Users\\Asher\\Documents\\School\\_Scriptie\\Data\\Data_Ngram\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return list met dict [{Land1}, {Land 1}]\n",
    "def get_csv_files(country_selection):\n",
    "    os.chdir(translated_csv_dir)\n",
    "    \n",
    "    country_return_list = []\n",
    "\n",
    "    # loop door alle folders die hierboven zijn geprint\n",
    "    for country in os.listdir():\n",
    "        \n",
    "        # filter op specifiek land (IN BOX 2)\n",
    "        if country in country_selection:\n",
    "            paths_dict = {}\n",
    "\n",
    "            # ga door alle inhoud van de landfolder heen\n",
    "            for root, dirs, files in os.walk(country):\n",
    "                file_data = []\n",
    "                \n",
    "                # loop door files van een folder\n",
    "                for file in files:\n",
    "                    \n",
    "                    file_data.append(file)\n",
    "\n",
    "                paths_dict[root] = file_data\n",
    "\n",
    "            country_return_list.append(paths_dict)\n",
    "        \n",
    "    return country_return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6eeb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# haal jaar maand en dag uit filename\n",
    "def extract_file_date(file_name):\n",
    "    \n",
    "    year_month_day = re.search(r\"\\d{4}-\\d{2}-\\d{2}\", file_name)\n",
    "#     year, month, day = year_month_day[0].split(\"-\")\n",
    "    \n",
    "    return year_month_day[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c538b90e",
   "metadata": {},
   "source": [
    "### Shingles uit CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b5df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geeft woorden en hoevaak deze voorkomen\n",
    "def get_victor_from_csv(path):\n",
    "    os.chdir(translated_csv_dir)\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    lines = df[\"value\"].to_list()\n",
    "    \n",
    "    victor = CountVectorizer(ngram_range=(1, 5))\n",
    "    \n",
    "    print(victor.fit_transform(lines))\n",
    "    counts = victor.fit_transform(lines).toarray()\n",
    "    headings = victor.get_feature_names_out()\n",
    "    \n",
    "    return headings, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd71d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functie testruimte\n",
    "# df_for_the_test = os.path.join(\"NL\", \"ParlaMint-NL_2014-04-16-tweedekamer-2.csv\")\n",
    "df_for_the_test = os.path.join(\"NL\", \"ParlaMint-NL_2014-12-18-tweedekamer-25.csv\")\n",
    "\n",
    "victor_output_headings, victor_output_counts = get_victor_from_csv(df_for_the_test)\n",
    "# print(len(victor_output_headings))\n",
    "# print(type(victor_output_counts))\n",
    "count_vect_df = pd.DataFrame(victor_output_counts, columns=victor_output_headings)\n",
    "\n",
    "display(count_vect_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b42f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Te langzame functie\n",
    "# geeft een merged vectorizer terug\n",
    "# def get_merged_victor(names1, vals1, names2, vals2):\n",
    "#     names = np.unique(np.append(names1, names2))\n",
    "#     vals = np.zeros(shape=(1,len(names)), dtype=int)\n",
    "    \n",
    "#     # voegt waarden toe aan vals\n",
    "#     def merge_vals(names_to_merge, vals_to_merge):\n",
    "#         m_vals_to_merge = np.zeros(shape=(1,len(vals_to_merge[0])), dtype=int)\n",
    "        \n",
    "#         # merge de rijen tot een enkele rij\n",
    "#         if len(vals_to_merge) != 1:\n",
    "            \n",
    "#             for row in vals_to_merge:\n",
    "#                 m_vals_to_merge = m_vals_to_merge + row\n",
    "                \n",
    "#         else:\n",
    "            \n",
    "#             m_vals_to_merge = vals_to_merge\n",
    "        \n",
    "#         # voeg de waarden toe aan de return set\n",
    "#         for iteration, name in enumerate(names_to_merge):\n",
    "#             pos = np.where(names == name)[0][0]\n",
    "#             count = m_vals_to_merge[0][iteration]\n",
    "            \n",
    "#             vals[0][pos] = vals[0][pos] + count\n",
    "    \n",
    "#     merge_vals(names1, vals1)\n",
    "#     merge_vals(names2, vals2)\n",
    "    \n",
    "#     return names, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289c570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_merged(rows):\n",
    "    return_rows = np.zeros(shape=(1,len(rows[0])), dtype=int)\n",
    "        \n",
    "    # merge de rijen tot een enkele rij\n",
    "    if len(rows) != 1:\n",
    "\n",
    "        for row in rows:\n",
    "            return_rows = return_rows + row\n",
    "\n",
    "    else:\n",
    "\n",
    "        return_rows = rows\n",
    "        \n",
    "    return return_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ced6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# functie testruimte\n",
    "# contents1 = ['aa bb cc dd']#,\n",
    "# #             'ee ff gg aa',\n",
    "# #             'jj kk']\n",
    "# contents2 = ['aa hh ii jj kk']\n",
    "\n",
    "# victor = CountVectorizer(ngram_range=(1, 1))\n",
    "# X1 = victor.fit_transform(contents1)\n",
    "\n",
    "# een = X1.toarray()\n",
    "# een_n = victor.get_feature_names_out()\n",
    "\n",
    "# print(een_n)\n",
    "# print(een, \"\\n\")\n",
    "\n",
    "# X2 = victor.fit_transform(contents2)\n",
    "\n",
    "# twee = X2.toarray()\n",
    "# twee_n = victor.get_feature_names_out()\n",
    "\n",
    "# print(twee_n)\n",
    "# print(twee, \"\\n\")\n",
    "\n",
    "# # n = np.unique(np.append(een_n, twee_n))\n",
    "# # v = np.append(twee, een.reshape((len(twee))))\n",
    "# # print(n, \"\\n\", v, \"\\n\")\n",
    "\n",
    "# n, v = get_merged_victor(een_n, een, twee_n, twee)\n",
    "# print(n, \"\\n\", v)\n",
    "\n",
    "# nmog meer functie testruimte\n",
    "# df_for_the_test1 = os.path.join(\"NL\", \"ParlaMint-NL_2014-04-16-tweedekamer-2.csv\")\n",
    "# df_for_the_test2 = os.path.join(\"NL\", \"ParlaMint-NL_2014-04-16-tweedekamer-3.csv\")\n",
    "\n",
    "# victor_output_counts, victor_output_headings = get_victor_from_csv(df_for_the_test1)\n",
    "# victor_output_counts2, victor_output_headings2 = get_victor_from_csv(df_for_the_test2)\n",
    "# n, v = get_merged_victor(victor_output_counts, victor_output_headings,\n",
    "#                          victor_output_counts2, victor_output_headings2)\n",
    "# print(n, \"\\n\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cafa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geeft een dict met dates als keys en files als vals\n",
    "def get_files_per_date(country):\n",
    "    files = get_csv_files(country)[0][country]\n",
    "    \n",
    "    dates_dict = {}\n",
    "    \n",
    "    # loop door alle files heen\n",
    "    for file in files:\n",
    "        \n",
    "        date = extract_file_date(file)\n",
    "        \n",
    "        if date in dates_dict.keys():\n",
    "            \n",
    "            dates_dict[date] += [file]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            dates_dict[date] = [file]\n",
    "            \n",
    "    return dates_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4f1bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maak een csv waar per date alle shingles in staan\n",
    "def create_shingle_csv(file, headings, counts):\n",
    "    os.chdir(ngram_csv_dir)\n",
    "    \n",
    "    with open(file, 'w', newline='', encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(headings)\n",
    "        \n",
    "        if len(counts) == 1:\n",
    "        \n",
    "            w.writerow(counts[0])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            w.writerow(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_exists(country, date):\n",
    "    os.chdir(ngram_csv_dir)\n",
    "    \n",
    "    path = os.path.join(country, (date + \".csv\"))\n",
    "    \n",
    "    return os.path.isfile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d016378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maakt een csv file aan per datum met shingles\n",
    "def create_shingle_per_day(country):\n",
    "    os.chdir(translated_csv_dir)\n",
    "    \n",
    "    dates_dict = get_files_per_date(country)\n",
    "    \n",
    "    # dingen voor overzicht in prints\n",
    "    timer = time.time()\n",
    "    total_dates = len(dates_dict.keys())\n",
    "    processed_dates = 0\n",
    "    \n",
    "    # ga elke date langs\n",
    "    for date, files in dates_dict.items():\n",
    "        processed_dates += 1\n",
    "        dates_percentage = round((processed_dates / total_dates) * 100, 2)\n",
    "        \n",
    "        if not get_ngram_exists(country, date):\n",
    "        \n",
    "            # ga elke file langs per date\n",
    "            for iteration, file in enumerate(files):\n",
    "\n",
    "                path = os.path.join(country, file)\n",
    "\n",
    "                # basis lijst neerzetten bij eerste iteratie\n",
    "                if iteration == 0:\n",
    "\n",
    "                    ngrams, counts = get_victor_from_csv(path)\n",
    "                    counts = get_rows_merged(counts)[0]\n",
    "                \n",
    "                else:\n",
    "\n",
    "                    new_ngrams, new_counts = get_victor_from_csv(path)\n",
    "\n",
    "                    # loop de ngram en counts\n",
    "                    for ngram, count in zip(new_ngrams, get_rows_merged(new_counts)[0]):\n",
    "\n",
    "                        # verander het ngram nummer als die al bestaat\n",
    "                        if ngram in ngrams:\n",
    "\n",
    "                            position = counts[np.where(ngrams == ngram)[0][0]]\n",
    "                            position = position + count\n",
    "\n",
    "                        # voeg de ngram toe aan ngrams en counts als die er nog niet is\n",
    "                        else:\n",
    "\n",
    "                            ngrams = np.append(ngrams, ngram)\n",
    "                            counts = np.append(counts, count)\n",
    "            \n",
    "            create_shingle_csv(os.path.join(country, (date + \".csv\")), ngrams, counts)\n",
    "            print(f\"Progress: {round((time.time() - timer) / 60, 2)}m, Uploaded: {date} ({dates_percentage}%)\")\n",
    "            \n",
    "        else:\n",
    "\n",
    "            print(f\"Skipping: {date} ({dates_percentage}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603973c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functie testruimte\n",
    "real_input = \"NL\"\n",
    "\n",
    "tngrams, tcounts = create_shingle_per_day(real_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # functie testruimte\n",
    "# ct_test = \"NL\"\n",
    "\n",
    "# date_test = get_files_per_date(ct_test)[\"2014-04-16\"]\n",
    "\n",
    "# for e, d in enumerate(date_test):\n",
    "#     path = os.path.join(ct_test, d)\n",
    "    \n",
    "#     if e == 0:\n",
    "        \n",
    "#         liness, countss = get_victor_from_csv(path)\n",
    "#         countss = get_rows_merged(countss)\n",
    "        \n",
    "#     else:\n",
    "        \n",
    "#         new_liness, new_countss = get_victor_from_csv(path)\n",
    "#         plsw = 0\n",
    "#         for headerr, counttt in zip(new_liness, get_rows_merged(new_countss)[0]):\n",
    "            \n",
    "#             if headerr in liness:\n",
    "                \n",
    "#                 actual_position = countss[np.where(liness == headerr)[0][0]]\n",
    "#                 actual_position = actual_position + counttt\n",
    "                \n",
    "#             else:\n",
    "                \n",
    "#                 liness = np.append(liness, headerr)\n",
    "#                 countss = np.append(countss, counttt)\n",
    "    \n",
    "#     print(len(liness))\n",
    "        \n",
    "# create_shingle_csv(path, liness, countss[0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7dd763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db21e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_countries = [\"BG\", \"CZ\", \"DK\", \"NL\", \"SI\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bbb063",
   "metadata": {},
   "source": [
    "### Oude code met Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d4724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Elastic host\n",
    "# es = Elasticsearch(\n",
    "#     hosts=[\n",
    "#             \"https://localhost:9200\"\n",
    "#     ],\n",
    "#     http_auth=(\"elastic\", \"NES9DZ-QwhanXAQf9caV\"), #basic_auth werkt niet met dsl queries\n",
    "# #     use_ssl=True,\n",
    "# #     verify_certs=False,\n",
    "#     ca_certs=\"./ca.crt\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee40f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # translated countries\n",
    "# translated_countries = [\"BG\", \"CZ\", \"DK\", \"NL\", \"SI\"]\n",
    "\n",
    "# # word counts df\n",
    "# word_count_csv = 'C:/Users/Asher/Documents/School/_Scriptie/Data/xml_word_counts.csv'\n",
    "\n",
    "# df_word_count = pd.read_csv(word_count_csv)\n",
    "\n",
    "# # display(df_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1408ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: input is {search_key: value, search_key2: value2}\n",
    "# # query function\n",
    "# def query(search_dict):\n",
    "#     processed_search_list = []\n",
    "    \n",
    "#     # loop door alle search elements heen\n",
    "#     for k, v in search_dict.items():\n",
    "#         processed_search_list.append({\"match_phrase\" : {k : v}})\n",
    "        \n",
    "#     # stel de uitkomst samen\n",
    "#     result = es.search(\n",
    "#     index = \"search\",\n",
    "#     size = 10000, # TODO: Zorg dat er een groter limit is dan 10000\n",
    "#     query = {\n",
    "#         \"bool\" : {\n",
    "#             \"must\": processed_search_list,\n",
    "#         },\n",
    "#     })\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ea29f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://copyprogramming.com/howto/using-shingles-and-fuzziness-in-elasticsearch-python-dsl\n",
    "# def make_dsl_query(fields):\n",
    "#     \"\"\"\n",
    "#     Construct a query\n",
    "#     \"\"\"\n",
    "#     my_query = Search(using=es, index=\"search\")\n",
    "#     if fields['country'] and fields['content_translated']:\n",
    "#         my_query = my_query.query(Q('bool', should=\n",
    "#                    [Q(\"match\", name__shingles=fields['country']),\n",
    "#                     Q(\"match\", surname__shingles=fields['content_translated'])]))\n",
    "#     return my_query\n",
    "\n",
    "# # if __name__ == '__main__':\n",
    "# my_query = make_dsl_query(fields={\"country\": \"NL\", \"content_translated\": \"bill\"})\n",
    "# response = my_query.execute()\n",
    "# print(response)\n",
    "# for hit in response:\n",
    "#     print(hit.meta.score, hit.name, hit.surname)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9986472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: input is {search_key: value, search_key2: value2}\n",
    "# # query function\n",
    "# def query_new(search_dict):\n",
    "#     processed_search_list = []\n",
    "    \n",
    "# #     search_dict[\"analyser\"] = \"standard_shingle\"\n",
    "    \n",
    "#     # loop door alle search elements heen\n",
    "#     for k, v in search_dict.items():\n",
    "#         processed_search_list.append({\"match_phrase\" : {k : v}})\n",
    "        \n",
    "#     # stel de uitkomst samen\n",
    "#     result = es.search(\n",
    "#     index = \"search\",\n",
    "#     size = 10000, # TODO: Zorg dat er een groter limit is dan 10000\n",
    "#     query = {\n",
    "#         \"bool\" : {\n",
    "#             \"must\": processed_search_list,\n",
    "#         },\n",
    "#     })\n",
    "    \n",
    "#     return result\n",
    "\n",
    "# result = query_new({\"country\": \"NL\", \"content_translated\": \"bill\"})\n",
    "\n",
    "# print(result[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2cfbd0",
   "metadata": {},
   "source": [
    "### Query testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b6fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: debate uploads opniew runnen om andere vertaalde landen ook toe te voegen\n",
    "\n",
    "# countries_returned = {}\n",
    "\n",
    "# for ctr in translated_countries:\n",
    "#     query_dit = query({\"content_translated\":\"bill\", \"country\":ctr})\n",
    "    \n",
    "#     for line in query_dit[\"hits\"][\"hits\"]:\n",
    "\n",
    "#         ct = line[\"_source\"][\"country\"]\n",
    "\n",
    "#         if ct in countries_returned.keys():\n",
    "\n",
    "#             countries_returned[ct] += 1\n",
    "\n",
    "#         else:\n",
    "\n",
    "#             countries_returned[ct] = 1\n",
    "    \n",
    "# print(countries_returned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
