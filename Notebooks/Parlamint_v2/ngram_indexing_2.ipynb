{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246010f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic host\n",
    "es = Elasticsearch(\n",
    "    hosts=[\n",
    "            \"https://localhost:9200\"\n",
    "    ],\n",
    "    http_auth=(\"elastic\", \"NES9DZ-QwhanXAQf9caV\"),\n",
    "#     use_ssl=True,\n",
    "    verify_certs=False,\n",
    "#     ca_certs=\"./ca.crt\"\n",
    ")\n",
    "\n",
    "# dir\n",
    "translated_csv_dir = r\"C:\\Users\\Asher\\Documents\\School\\_Scriptie\\Data\\Data_Userlines_CSV\"\n",
    "ngram_csv_dir = r\"C:\\Users\\Asher\\Documents\\School\\_Scriptie\\Data\\Data_Ngram\"\n",
    "\n",
    "# word counts df\n",
    "word_count_csv = 'C:/Users/Asher/Documents/School/_Scriptie/Data/xml_word_counts.csv'\n",
    "\n",
    "df_word_count = pd.read_csv(word_count_csv)\n",
    "\n",
    "display(df_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return list met dict [{Land1}, {Land 1}]\n",
    "def get_csv_files(country_selection):\n",
    "    os.chdir(translated_csv_dir)\n",
    "    \n",
    "    country_return_list = []\n",
    "\n",
    "    # loop door alle folders die hierboven zijn geprint\n",
    "    for country in os.listdir():\n",
    "        \n",
    "        # filter op specifiek land (IN BOX 2)\n",
    "        if country in country_selection:\n",
    "            paths_dict = {}\n",
    "\n",
    "            # ga door alle inhoud van de landfolder heen\n",
    "            for root, dirs, files in os.walk(country):\n",
    "                file_data = []\n",
    "                \n",
    "                # loop door files van een folder\n",
    "                for file in files:\n",
    "                    \n",
    "                    file_data.append(file)\n",
    "\n",
    "                paths_dict[root] = file_data\n",
    "\n",
    "            country_return_list.append(paths_dict)\n",
    "        \n",
    "    return country_return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6eeb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# haal jaar maand en dag uit filename\n",
    "def extract_file_date(file_name):\n",
    "    \n",
    "    year_month_day = re.search(r\"\\d{4}-\\d{2}-\\d{2}\", file_name)\n",
    "#     year, month, day = year_month_day[0].split(\"-\")\n",
    "    \n",
    "    return year_month_day[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c538b90e",
   "metadata": {},
   "source": [
    "### Shingles uit CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b14a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geeft een dict met dates als keys en files als vals\n",
    "def get_files_per_date(country, after=None):\n",
    "    files = get_csv_files(country)[0][country]\n",
    "    \n",
    "    dates_dict = {}\n",
    "    \n",
    "    if after is not None:\n",
    "        \n",
    "        after = time.mktime(datetime.datetime.strptime(after, \"%Y-%m-%d\").timetuple())\n",
    "    \n",
    "    # loop door alle files heen\n",
    "    for file in files:\n",
    "        \n",
    "        date = extract_file_date(file)\n",
    "        \n",
    "        # filter al geuploade dates uit de dict\n",
    "        if after is not None:\n",
    "            timestamp = time.mktime(datetime.datetime.strptime(date, \"%Y-%m-%d\").timetuple())\n",
    "            \n",
    "            if (timestamp - after) <= 0:\n",
    "                \n",
    "                continue\n",
    "        \n",
    "        if date in dates_dict.keys():\n",
    "            \n",
    "            dates_dict[date] += [file]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            dates_dict[date] = [file]\n",
    "            \n",
    "    return dates_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd195e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maakt paths aan voor alle files die bij een date horen\n",
    "def get_date_paths(root, files):\n",
    "    os.chdir(translated_csv_dir)\n",
    "    \n",
    "    paths = []\n",
    "    \n",
    "    for file in files:\n",
    "        paths.append(os.path.join(root, file))\n",
    "        \n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maakt ngrams van alle tekst in een csv file\n",
    "def get_date_vocabulary(paths):\n",
    "    os.chdir(translated_csv_dir)\n",
    "    \n",
    "    vocabulary = np.array(())\n",
    "    \n",
    "    for path in paths:\n",
    "        df = pd.read_csv(path)\n",
    "    \n",
    "        # slecht vertaalde notebooks met alleen een index negeren\n",
    "        if len(df.index) == 0:\n",
    "            continue\n",
    "            \n",
    "        lines = df[\"value\"].to_list()\n",
    "    \n",
    "        victor = CountVectorizer(ngram_range=(1, 5), token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "        victor.fit_transform(lines)\n",
    "        \n",
    "        vocabulary = np.unique(np.hstack((vocabulary, victor.get_feature_names_out()))) \n",
    "    \n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae84629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_counts(paths, vocabulary):\n",
    "    os.chdir(translated_csv_dir)\n",
    "    \n",
    "    counts = np.zeros(shape=(len(vocabulary)), dtype=int)\n",
    "    \n",
    "    for path in paths:\n",
    "        df = pd.read_csv(path)\n",
    "    \n",
    "        # slecht vertaalde notebooks met alleen een index negeren\n",
    "        if len(df.index) == 0:\n",
    "            continue\n",
    "            \n",
    "        lines = df[\"value\"].to_list()\n",
    "    \n",
    "        victor = CountVectorizer(ngram_range=(1, 5), token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "        victor.fit_transform(vocabulary)\n",
    "        \n",
    "        counts = counts + np.sum(victor.transform(lines).toarray(), axis=0)\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541b0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_es_date_dict(vocabulary, country, date, counts, elastic_id, index=\"ngrams\"):\n",
    "    word_total = df_word_count[(df_word_count[\"date\"] == date) & (df_word_count[\"country\"] == country)][\"words\"].values[0]\n",
    "    year, month, day = re.search(r\"\\d{4}-\\d{2}-\\d{2}\", date)[0].split(\"-\")\n",
    "#     word_total = 32 # voor \"test\" dataset\n",
    "    bulk = []\n",
    "    \n",
    "    for ngram, count in zip(vocabulary, counts):\n",
    "        content_dict, es_content_dict = {}, {}\n",
    "        \n",
    "        # start altijd op 1 (geef laatst ingevoerde id als input)\n",
    "        elastic_id += 1\n",
    "        \n",
    "        # entry inhoud\n",
    "        content_dict[\"ngram\"] = ngram\n",
    "        content_dict[\"country\"] = country\n",
    "        content_dict[\"year\"] = year\n",
    "        content_dict[\"month\"] = month\n",
    "        content_dict[\"day\"] = day\n",
    "        content_dict[\"count\"] = count\n",
    "        content_dict[\"percentage\"] = round(((count * len(ngram.split(\" \"))) / word_total) * 100, 4)\n",
    "        \n",
    "        # entry technische dingen\n",
    "        es_content_dict[\"_index\"] = index\n",
    "        es_content_dict[\"_id\"] = elastic_id\n",
    "        es_content_dict[\"_source\"] = content_dict\n",
    "        \n",
    "        # voeg entry toe aan bulk return lijst\n",
    "        bulk.append(es_content_dict)\n",
    "        \n",
    "    return bulk, elastic_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b7491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # functie testruimte\n",
    "# test_dates_dict = get_files_per_date(\"test\")\n",
    "# print(test_dates_dict)\n",
    "# test_paths = get_date_paths(\"test\", test_dates_dict['2014-04-16'])\n",
    "# print(test_paths)\n",
    "# test_vocabulary = get_date_vocabulary(test_paths)\n",
    "# print(test_vocabulary)\n",
    "# test_counts = get_date_counts(test_paths, test_vocabulary)\n",
    "# print(test_counts)\n",
    "# test_date_es_dict = get_es_date_dict(test_vocabulary, \"test\", '2014-04-16', test_counts, 0)\n",
    "# print(test_date_es_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c278b1f",
   "metadata": {},
   "source": [
    "### Countvectorizer 1.3\n",
    "Elastic (index = ngrams):\n",
    "- | Shingle | Land | Jaar | Maand | Dag | Aantal | Percentage |\n",
    " - Shingles doen voor een datum, voor een land\n",
    " - Percentage berekenen\n",
    " - Uploaden in ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1772ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_ngrams(countries, elastic_id=0, after=None):\n",
    "    \n",
    "    for country in countries:\n",
    "        \n",
    "        # ga verder bij een specifieke datum vanaf een specifiek id\n",
    "        if country == countries[0]:\n",
    "            \n",
    "            dates = get_files_per_date(country, after=after)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            dates = get_files_per_date(country)\n",
    "        \n",
    "        # dingen voor overzicht in prints\n",
    "        timer = time.time()\n",
    "        total_dates = len(dates.keys())\n",
    "        processed_dates = 0\n",
    "        \n",
    "        for date in dates:\n",
    "            processed_dates += 1\n",
    "            dates_percentage = round((processed_dates / total_dates) * 100, 2)\n",
    "            \n",
    "            paths = get_date_paths(country, dates[date])\n",
    "            \n",
    "            vocabulary = get_date_vocabulary(paths)\n",
    "            counts = get_date_counts(paths, vocabulary)\n",
    "            \n",
    "            elastic_dict, elastic_id = get_es_date_dict(vocabulary, country, date, counts, elastic_id)\n",
    "            \n",
    "            helpers.bulk(es, elastic_dict)\n",
    "            print(f\"Progress: {round((time.time() - timer) / 60, 2)}m, Uploaded: {date} {country} ({dates_percentage}%), Last Id: {elastic_id}\")\n",
    "        \n",
    "        print(f\"Progress: {country} finished\")\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff5fc0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# werkende landen\n",
    "# uploaded = []\n",
    "\n",
    "translated_countries = [\"BG\", \"CZ\", \"DK\", \"NL\", \"SI\", \"GB\"]\n",
    "\n",
    "upload = upload_ngrams(translated_countries) #, 662485289, \"2019-01-15\"\n",
    "\n",
    "print(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c66ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress: 93.87m, Uploaded: 2020-07-31 BG (100.0%), Last Id: 64824684\n",
    "\n",
    "# Progress: 234.16m, Uploaded: 2021-04-01 CZ (100.0%), Last Id: 144041510\n",
    "\n",
    "# Progress: 54.36m, Uploaded: 2017-01-11 DK (37.93%), Last Id: 179242678\n",
    "# Progress: 54.46m, Uploaded: 2017-01-12 DK (38.08%), Last Id: 179311571\n",
    "# Progress: 81.62m, Uploaded: 2020-09-29 DK (100.0%), Last Id: 232731837\n",
    "\n",
    "# Progress: 303.28m, Uploaded: 2019-03-13 NL (73.06%), Last Id: 344101599\n",
    "# Progress: 109.18m, Uploaded: 2020-11-03 NL (100.0%), Last Id: 385908154\n",
    "\n",
    "# Progress: 32.42m, Uploaded: 2016-03-29 SI (28.25%), Last Id: 406585230\n",
    "# Progress: 53.01m, Uploaded: 2018-12-17 SI (66.55%), Last Id: 439749779\n",
    "# Progress: 27.21m, Uploaded: 2020-07-16 SI (100.0%), Last Id: 457496522\n",
    "\n",
    "# Progress: 180.32m, Uploaded: 2017-01-24 GB (33.61%), Last Id: 563223404\n",
    "# Progress: 172.62m, Uploaded: 2019-01-15 GB (46.53%), Last Id: 662485289\n",
    "\n",
    "# TransportError: TransportError(429, 'circuit_breaking_exception', '[parent] Data too large, data for [<http_request>] would be [512818540/489mb], which is larger than the limit of [510027366/486.3mb], real usage: [512657568/488.9mb], new bytes reserved: [160972/157.1kb], usages [model_inference=0/0b, inflight_requests=160972/157.1kb, request=0/0b, fielddata=0/0b, eql_sequence=0/0b]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb1da74",
   "metadata": {},
   "source": [
    "### Countvectorizer 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # geef true als een bestand bestaat\n",
    "# def get_ngram_exists(country, date):\n",
    "#     os.chdir(ngram_csv_dir)\n",
    "    \n",
    "#     path = os.path.join(country, (date + \".csv\"))\n",
    "    \n",
    "#     return os.path.isfile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0639510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # geeft woorden en hoevaak deze voorkomen\n",
    "# def get_victor_from_csv(path, vocab=None, ngrams=5):\n",
    "#     os.chdir(translated_csv_dir)\n",
    "    \n",
    "#     df = pd.read_csv(path)\n",
    "    \n",
    "#     # slecht vertaalde notebooks met alleen een index negeren\n",
    "#     if len(df.index) == 0:\n",
    "#         return np.array(()), np.array(())\n",
    "    \n",
    "#     lines = df[\"value\"].to_list()\n",
    "    \n",
    "#     victor = CountVectorizer(ngram_range=(1, ngrams))\n",
    "    \n",
    "#     if vocab is not None:\n",
    "        \n",
    "#         victor.fit_transform(vocab)\n",
    "#         counts = victor.transform(lines).toarray()\n",
    "#         print(\"inserted vocac\")\n",
    "        \n",
    "#     else:\n",
    "    \n",
    "#         counts = victor.fit_transform(lines).toarray()\n",
    "    \n",
    "#     # vocab is een andere mogelijkheid?\n",
    "# #     headings = victor.vocabulary_\n",
    "#     headings = victor.get_feature_names_out()\n",
    "    \n",
    "#     return headings, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c4b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functie testruimte\n",
    "# df_for_the_test = os.path.join(\"NL\", \"ParlaMint-NL_2014-04-16-tweedekamer-2.csv\")\n",
    "# df_for_the_test = os.path.join(\"NL\", \"ParlaMint-NL_2014-12-18-tweedekamer-25.csv\")\n",
    "\n",
    "# victor_output_headings, victor_output_counts = get_victor_from_csv(df_for_the_test)\n",
    "# print(len(victor_output_headings))\n",
    "# print(type(victor_output_counts))\n",
    "# count_vect_df = pd.DataFrame(victor_output_counts, columns=victor_output_headings)\n",
    "\n",
    "# display(count_vect_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67255077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_vocabulary(country):\n",
    "#     os.chdir(translated_csv_dir)\n",
    "    \n",
    "#     dates_dict = get_files_per_date(country)\n",
    "    \n",
    "#     # dingen voor overzicht in prints\n",
    "#     timer = time.time()\n",
    "#     total_dates = len(dates_dict.keys())\n",
    "#     processed_dates = 0\n",
    "    \n",
    "#     vocabulary = np.array(())\n",
    "    \n",
    "#     # ga elke date langs\n",
    "#     for date, files in dates_dict.items():\n",
    "#         processed_dates += 1\n",
    "#         dates_percentage = round((processed_dates / total_dates) * 100, 2)\n",
    "        \n",
    "#         # ga elke file langs per date\n",
    "#         for file in files:\n",
    "#             path = os.path.join(country, file)\n",
    "\n",
    "#             headings, count = get_victor_from_csv(path, None, 5)\n",
    "            \n",
    "#             vocabulary = np.unique(np.hstack((vocabulary, headings)))\n",
    "            \n",
    "#         print(f\"Progress: {round((time.time() - timer) / 60, 2)}m, Uploaded: {date} ({dates_percentage}%), Size: {len(vocabulary)}\")\n",
    "#     return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # functie testruimte\n",
    "# real_input = \"NL\"\n",
    "\n",
    "# test_vocabulary = create_vocabulary(real_input)\n",
    "\n",
    "# print(len(test_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc9864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_shingle_testing(country):\n",
    "#     os.chdir(translated_csv_dir)\n",
    "    \n",
    "#     dates_dict = get_files_per_date(country)\n",
    "    \n",
    "#     # dingen voor overzicht in prints\n",
    "#     timer = time.time()\n",
    "    \n",
    "#     longheadings = np.array(['aa', 'bb', 'cc', 'dd', 'ee', 'ff', 'gg', 'hh', 'ii', 'jj'])\n",
    "    \n",
    "#     for file in dates_dict[\"2014-04-16\"]:\n",
    "#         path = os.path.join(country, file)\n",
    "        \n",
    "#         headings, count = get_victor_from_csv(path, None, 1)\n",
    "\n",
    "#         print(headings, np.sum(count, axis=0))\n",
    "\n",
    "#     print(round((time.time() - timer) / 60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # functie testruimte\n",
    "# real_input = \"test\"\n",
    "\n",
    "# create_shingle_testing(real_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1483c1a",
   "metadata": {},
   "source": [
    "### Countvectorizer 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # maak een csv waar per date alle shingles in staan\n",
    "# def create_shingle_csv(file, headings, counts):\n",
    "#     os.chdir(ngram_csv_dir)\n",
    "    \n",
    "#     with open(file, 'w', newline='', encoding=\"utf-8\") as f:\n",
    "#         w = csv.writer(f)\n",
    "#         w.writerow(headings)\n",
    "        \n",
    "#         if len(counts) == 1:\n",
    "        \n",
    "#             w.writerow(counts[0])\n",
    "            \n",
    "#         else:\n",
    "            \n",
    "#             w.writerow(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6537239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # oude funtie (np.sum(x, axis=0) doet hetzelfde)\n",
    "# def get_rows_merged(rows):\n",
    "#     return_rows = np.zeros(shape=(1,len(rows[0])), dtype=int)\n",
    "        \n",
    "#     # merge de rijen tot een enkele rij\n",
    "#     if len(rows) != 1:\n",
    "\n",
    "#         for row in rows:\n",
    "#             return_rows = return_rows + row\n",
    "\n",
    "#     else:\n",
    "\n",
    "#         return_rows = rows\n",
    "        \n",
    "#     return return_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d016378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # maakt een csv file aan per datum met shingles\n",
    "# def create_shingle_per_day(country):\n",
    "#     os.chdir(translated_csv_dir)\n",
    "    \n",
    "#     dates_dict = get_files_per_date(country)\n",
    "    \n",
    "#     # dingen voor overzicht in prints\n",
    "#     timer = time.time()\n",
    "#     total_dates = len(dates_dict.keys())\n",
    "#     processed_dates = 0\n",
    "    \n",
    "#     # ga elke date langs\n",
    "#     for date, files in dates_dict.items():\n",
    "#         processed_dates += 1\n",
    "#         dates_percentage = round((processed_dates / total_dates) * 100, 2)\n",
    "        \n",
    "#         if not get_ngram_exists(country, date):\n",
    "        \n",
    "#             # ga elke file langs per date\n",
    "#             for iteration, file in enumerate(files):\n",
    "\n",
    "#                 path = os.path.join(country, file)\n",
    "\n",
    "#                 # basis lijst neerzetten bij eerste iteratie\n",
    "#                 if iteration == 0:\n",
    "\n",
    "#                     ngrams, counts = get_victor_from_csv(path)\n",
    "#                     counts = get_rows_merged(counts)[0]\n",
    "                \n",
    "#                 else:\n",
    "\n",
    "#                     new_ngrams, new_counts = get_victor_from_csv(path)\n",
    "\n",
    "#                     # loop de ngram en counts\n",
    "#                     for ngram, count in zip(new_ngrams, get_rows_merged(new_counts)[0]):\n",
    "\n",
    "#                         # verander het ngram nummer als die al bestaat\n",
    "#                         if ngram in ngrams:\n",
    "\n",
    "#                             position = counts[np.where(ngrams == ngram)[0][0]]\n",
    "#                             position = position + count\n",
    "\n",
    "#                         # voeg de ngram toe aan ngrams en counts als die er nog niet is\n",
    "#                         else:\n",
    "\n",
    "#                             ngrams = np.append(ngrams, ngram)\n",
    "#                             counts = np.append(counts, count)\n",
    "            \n",
    "#             create_shingle_csv(os.path.join(country, (date + \".csv\")), ngrams, counts)\n",
    "#             print(f\"Progress: {round((time.time() - timer) / 60, 2)}m, Uploaded: {date} ({dates_percentage}%)\")\n",
    "            \n",
    "#         else:\n",
    "\n",
    "#             print(f\"Skipping: {date} ({dates_percentage}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603973c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # functie testruimte\n",
    "# real_input = \"NL\"\n",
    "\n",
    "# tngrams, tcounts = create_shingle_per_day(real_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811e1c72",
   "metadata": {},
   "source": [
    "### Countvectorizer 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a4683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Te langzame functie\n",
    "# geeft een merged vectorizer terug\n",
    "# def get_merged_victor(names1, vals1, names2, vals2):\n",
    "#     names = np.unique(np.append(names1, names2))\n",
    "#     vals = np.zeros(shape=(1,len(names)), dtype=int)\n",
    "    \n",
    "#     # voegt waarden toe aan vals\n",
    "#     def merge_vals(names_to_merge, vals_to_merge):\n",
    "#         m_vals_to_merge = np.zeros(shape=(1,len(vals_to_merge[0])), dtype=int)\n",
    "        \n",
    "#         # merge de rijen tot een enkele rij\n",
    "#         if len(vals_to_merge) != 1:\n",
    "            \n",
    "#             for row in vals_to_merge:\n",
    "#                 m_vals_to_merge = m_vals_to_merge + row\n",
    "                \n",
    "#         else:\n",
    "            \n",
    "#             m_vals_to_merge = vals_to_merge\n",
    "        \n",
    "#         # voeg de waarden toe aan de return set\n",
    "#         for iteration, name in enumerate(names_to_merge):\n",
    "#             pos = np.where(names == name)[0][0]\n",
    "#             count = m_vals_to_merge[0][iteration]\n",
    "            \n",
    "#             vals[0][pos] = vals[0][pos] + count\n",
    "    \n",
    "#     merge_vals(names1, vals1)\n",
    "#     merge_vals(names2, vals2)\n",
    "    \n",
    "#     return names, vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bbb063",
   "metadata": {},
   "source": [
    "### Oude code met Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d4724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Elastic host\n",
    "# es = Elasticsearch(\n",
    "#     hosts=[\n",
    "#             \"https://localhost:9200\"\n",
    "#     ],\n",
    "#     http_auth=(\"elastic\", \"NES9DZ-QwhanXAQf9caV\"), #basic_auth werkt niet met dsl queries\n",
    "# #     use_ssl=True,\n",
    "# #     verify_certs=False,\n",
    "#     ca_certs=\"./ca.crt\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee40f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # translated countries\n",
    "# translated_countries = [\"BG\", \"CZ\", \"DK\", \"NL\", \"SI\"]\n",
    "\n",
    "# # word counts df\n",
    "# word_count_csv = 'C:/Users/Asher/Documents/School/_Scriptie/Data/xml_word_counts.csv'\n",
    "\n",
    "# df_word_count = pd.read_csv(word_count_csv)\n",
    "\n",
    "# # display(df_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1408ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: input is {search_key: value, search_key2: value2}\n",
    "# # query function\n",
    "# def query(search_dict):\n",
    "#     processed_search_list = []\n",
    "    \n",
    "#     # loop door alle search elements heen\n",
    "#     for k, v in search_dict.items():\n",
    "#         processed_search_list.append({\"match_phrase\" : {k : v}})\n",
    "        \n",
    "#     # stel de uitkomst samen\n",
    "#     result = es.search(\n",
    "#     index = \"search\",\n",
    "#     size = 10000, # TODO: Zorg dat er een groter limit is dan 10000\n",
    "#     query = {\n",
    "#         \"bool\" : {\n",
    "#             \"must\": processed_search_list,\n",
    "#         },\n",
    "#     })\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ea29f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://copyprogramming.com/howto/using-shingles-and-fuzziness-in-elasticsearch-python-dsl\n",
    "# def make_dsl_query(fields):\n",
    "#     \"\"\"\n",
    "#     Construct a query\n",
    "#     \"\"\"\n",
    "#     my_query = Search(using=es, index=\"search\")\n",
    "#     if fields['country'] and fields['content_translated']:\n",
    "#         my_query = my_query.query(Q('bool', should=\n",
    "#                    [Q(\"match\", name__shingles=fields['country']),\n",
    "#                     Q(\"match\", surname__shingles=fields['content_translated'])]))\n",
    "#     return my_query\n",
    "\n",
    "# # if __name__ == '__main__':\n",
    "# my_query = make_dsl_query(fields={\"country\": \"NL\", \"content_translated\": \"bill\"})\n",
    "# response = my_query.execute()\n",
    "# print(response)\n",
    "# for hit in response:\n",
    "#     print(hit.meta.score, hit.name, hit.surname)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9986472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: input is {search_key: value, search_key2: value2}\n",
    "# # query function\n",
    "# def query_new(search_dict):\n",
    "#     processed_search_list = []\n",
    "    \n",
    "# #     search_dict[\"analyser\"] = \"standard_shingle\"\n",
    "    \n",
    "#     # loop door alle search elements heen\n",
    "#     for k, v in search_dict.items():\n",
    "#         processed_search_list.append({\"match_phrase\" : {k : v}})\n",
    "        \n",
    "#     # stel de uitkomst samen\n",
    "#     result = es.search(\n",
    "#     index = \"search\",\n",
    "#     size = 10000, # TODO: Zorg dat er een groter limit is dan 10000\n",
    "#     query = {\n",
    "#         \"bool\" : {\n",
    "#             \"must\": processed_search_list,\n",
    "#         },\n",
    "#     })\n",
    "    \n",
    "#     return result\n",
    "\n",
    "# result = query_new({\"country\": \"NL\", \"content_translated\": \"bill\"})\n",
    "\n",
    "# print(result[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2cfbd0",
   "metadata": {},
   "source": [
    "### Query testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b6fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: debate uploads opniew runnen om andere vertaalde landen ook toe te voegen\n",
    "\n",
    "# countries_returned = {}\n",
    "\n",
    "# for ctr in translated_countries:\n",
    "#     query_dit = query({\"content_translated\":\"bill\", \"country\":ctr})\n",
    "    \n",
    "#     for line in query_dit[\"hits\"][\"hits\"]:\n",
    "\n",
    "#         ct = line[\"_source\"][\"country\"]\n",
    "\n",
    "#         if ct in countries_returned.keys():\n",
    "\n",
    "#             countries_returned[ct] += 1\n",
    "\n",
    "#         else:\n",
    "\n",
    "#             countries_returned[ct] = 1\n",
    "    \n",
    "# print(countries_returned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
