{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05309226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a5dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic host\n",
    "es = Elasticsearch(\n",
    "    hosts=[\n",
    "            \"https://localhost:9200\"\n",
    "    ],\n",
    "    basic_auth=(\"elastic\", \"NES9DZ-QwhanXAQf9caV\"),\n",
    "#     use_ssl=True,\n",
    "#     verify_certs=False,\n",
    "    ca_certs=\"./ca.crt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af21406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word counts df\n",
    "word_count_csv = 'C:/Users/Asher/Documents/School/_Scriptie/Data/xml_word_counts.csv'\n",
    "\n",
    "df_word_count = pd.read_csv(word_count_csv)\n",
    "\n",
    "display(df_word_count)\n",
    "\n",
    "test_count = df_word_count[df_word_count[\"filename\"] == 'ParlaMint-BE_2014-06-19-54-plenair-ip001x.xml'][\"words\"].values[0]\n",
    "print(test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb7b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: input is {search_key: value, search_key2: value2}\n",
    "# query function\n",
    "def query(search_dict):\n",
    "    processed_search_list = []\n",
    "    \n",
    "    # loop door alle search elements heen\n",
    "    for k, v in search_dict.items():\n",
    "        processed_search_list.append({\"match_phrase\" : {k : v}})\n",
    "        \n",
    "    # stel de uitkomst samen\n",
    "    result = es.search(\n",
    "    index = \"search\",\n",
    "    size = 10000, # TODO: Zorg dat er een groter limit is dan 10000\n",
    "    query = {\n",
    "        \"bool\" : {\n",
    "            \"must\": processed_search_list,\n",
    "        },\n",
    "    })\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1b61d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oude functie waarmee ik een andere manier van Ngram maken testte op snelheid\n",
    "# # NOTE: input is {search_key: value, search_key2: value2}\n",
    "\n",
    "# # query function\n",
    "# def query_termvectors(search_dict, countries=[\"BE\"]): #, \"BE\", \"FR\"\n",
    "#     # de zoekterm\n",
    "#     term = search_dict[\"content_simplified\"]\n",
    "    \n",
    "#     # return dataframe\n",
    "#     df = pd.DataFrame({'date': [],\n",
    "#                       'percentage': [],\n",
    "#                       'country': []\n",
    "#                       })\n",
    "    \n",
    "#     # doe een query per land\n",
    "#     for country in countries:\n",
    "#         search_dict[\"country\"] = \"BE\"\n",
    "    \n",
    "#         query_output = query(search_dict)\n",
    "\n",
    "#         # files, ids\n",
    "#         files = {}\n",
    "        \n",
    "#         # dates, files\n",
    "#         dates = {}\n",
    "\n",
    "#         for res in query_output['hits']['hits']:\n",
    "#             seg_id = res[\"_source\"][\"file\"]\n",
    "#             date = res[\"_source\"][\"year\"] + res[\"_source\"][\"month\"] + res[\"_source\"][\"day\"]\n",
    "            \n",
    "#             if seg_id in files:\n",
    "                \n",
    "#                 files[seg_id] += [res[\"_id\"]]\n",
    "                \n",
    "#             else:\n",
    "                \n",
    "#                 files[seg_id] = [res[\"_id\"]]\n",
    "                \n",
    "#             if date in dates and seg_id not in dates[date]:\n",
    "                \n",
    "#                 dates[date] += [seg_id]\n",
    "                \n",
    "#             else:\n",
    "                \n",
    "#                 dates[date] = [seg_id]\n",
    "        \n",
    "#         # loop door alle files op een date heen\n",
    "#         for date in dates:\n",
    "#             files_per_date = dates[date]\n",
    "#             print(date, files_per_date , \"\\n\")\n",
    "#             for file in files_per_date:\n",
    "#                 print(date, file, \"\\n\")\n",
    "#                 file_term_freq = 0\n",
    "\n",
    "#                 for ids in files[file]:\n",
    "#                     print(ids)\n",
    "#                     result = es.mtermvectors(\n",
    "#                         ids=[ids], \n",
    "#                         index=\"search\",\n",
    "#                         term_statistics=False,\n",
    "#                         field_statistics=False,\n",
    "#                         offsets=False,\n",
    "#                         payloads=False,\n",
    "#                         positions=False,\n",
    "#                         fields=[\"content_simplified\"]\n",
    "#                     )\n",
    "\n",
    "#                     id_term_freq = result[\"docs\"][0][\"term_vectors\"][\"content_simplified\"][\"terms\"][term][\"term_freq\"]\n",
    "#                     file_term_freq = file_term_freq + int(id_term_freq)\n",
    "\n",
    "#                 word_total = df_word_count[df_word_count[\"filename\"] == file][\"words\"].values[0]    \n",
    "# #                 print(file, file_term_freq, word_total)\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403756ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Oude testruimte\n",
    "# start_time = time.time()\n",
    "\n",
    "# test_term = \"democratie\"\n",
    "\n",
    "# test_newgram = query_termvectors({\"content_simplified\":test_term})\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# print(test_newgram[\"docs\"][0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ddeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query testruimte\n",
    "start_time = time.time()\n",
    "\n",
    "# de query zelf\n",
    "# test_result = query({\"content_simplified\":\"ete\", \n",
    "#                      \"person_simplified\":\"FreDeriC BARBIER\", \n",
    "#                      \"country\":\"FR\"})\n",
    "\n",
    "# test_result = query({\"content_simplified\":\"groen\",\n",
    "#                      \"party\":\"SP\",\n",
    "#                      \"year\":\"2018\"})\n",
    "\n",
    "test_result = query({\"content_simplified\":\"democratie\",\n",
    "                    \"segment\":\"ParlaMint-NL_2017-02-08-tweedekamer-10.u200\"})\n",
    "\n",
    "print(\"Got %d Hits:\" % test_result['hits']['total']['value'])\n",
    "\n",
    "for hit in test_result['hits']['hits']:\n",
    "    print(\"%(person)s (%(party)s) \\n(%(year)s-%(month)s-%(day)s) %(segment)s:\\n %(content)s \\n\" % hit[\"_source\"])\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a63959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oude functie\n",
    "# def get_file_name(file):\n",
    "#     file = file.split('.')[0]+'.xml'\n",
    "        \n",
    "#     if 'FR' in file:\n",
    "#         file = file.split('_u')[0]+'.xml'\n",
    "    \n",
    "#     return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_percentage(row):\n",
    "    word_total = df_word_count[df_word_count[\"filename\"] == row[\"file\"]][\"words\"].values[0]\n",
    "    return (row[\"percentage\"] / word_total) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968fac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neemt een query als input en geeft een df terug voor plotly express\n",
    "# TODO: Standaardlanden fixen en zorgen dat de afweging voor zoeken met translation gemaakt kan worden\n",
    "def get_ngram_df(query_input, timespan=\"years\", countries=[\"NL\", \"BE\", \"FR\"]):\n",
    "    \n",
    "    query_input_words = len(query_input[\"content_simplified\"].split(\" \"))\n",
    "    \n",
    "    df = pd.DataFrame({'date': [],\n",
    "                      'percentage': [],\n",
    "                      'country': [],\n",
    "                      'file': []})\n",
    "    \n",
    "    # doe een query per land\n",
    "    for country in countries:\n",
    "        query_input[\"country\"] = country\n",
    "        query_result = query(query_input)[\"hits\"][\"hits\"]\n",
    "    \n",
    "        # loop door elk resultaat\n",
    "        for hit in query_result:\n",
    "            src = hit[\"_source\"]\n",
    "\n",
    "            # verschillende weergaven\n",
    "            if timespan == \"years\":\n",
    "                date = \"{}-{}-{}\".format(src[\"year\"], 1, 1)\n",
    "            elif timespan == \"months\":\n",
    "                date = \"{}-{}-{}\".format(src[\"year\"], src[\"month\"], 1)\n",
    "            else:\n",
    "                date = \"{}-{}-{}\".format(src[\"year\"], src[\"month\"], src[\"day\"])\n",
    "\n",
    "            file = src[\"file\"]\n",
    "\n",
    "            df.loc[len(df.index)] = [date,\n",
    "                                     (query_input_words * (src[\"content_simplified\"].count(query_input[\"content_simplified\"]))),\n",
    "                                     country,\n",
    "                                     file]\n",
    "\n",
    "    # krijg het totaal aantal hits binnen 1 bestand van de zoekterm\n",
    "    df[\"percentage\"] = df.groupby(\"file\")[\"percentage\"].transform(\"sum\")\n",
    "\n",
    "    # schoon de df weer op\n",
    "    df = df.drop_duplicates([\"date\", \"percentage\", \"country\", \"file\"])\n",
    "    df = df.loc[df[\"percentage\"] != 0]\n",
    "\n",
    "    # reken per document het ngram percentage uit\n",
    "    df[\"percentage\"] = df.apply(get_word_percentage, axis=1)\n",
    "\n",
    "    # voeg alle percentages op dezelfde dag samen\n",
    "    df[\"percentage\"] = df.groupby([\"country\", \"date\"])[\"percentage\"].transform(\"sum\")\n",
    "\n",
    "    # ga elke date langs om het totale percentage te delen door het aantal files vand de dag\n",
    "    countries = list(dict.fromkeys(df[\"country\"].tolist()))\n",
    "\n",
    "    # deel per land en date de percentage som door het aantal documenten op de datum\n",
    "    for country in countries:\n",
    "        dates = list(dict.fromkeys(df[df[\"country\"] == country][\"date\"].tolist()))\n",
    "\n",
    "        for date in dates:\n",
    "\n",
    "            # deel het totale percentage door het totale aantal rows (van een date en country)\n",
    "            count = len(df[(df[\"date\"] == date) & (df[\"country\"] == country)])\n",
    "            df.update(df.loc[(df[\"country\"] == country) & (df[\"date\"] == date)][\"percentage\"].apply(lambda x: (x / count)))\n",
    "\n",
    "    # gooi de dupes eruit\n",
    "    df = df.drop_duplicates([\"date\", \"country\"]).drop(\"file\", axis=1)\n",
    "    \n",
    "    return df.sort_values(by=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600e36d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "test_term = \"democratie\"\n",
    "\n",
    "test_newgram = {\"content_simplified\":test_term}\n",
    "\n",
    "test_ngram_df = get_ngram_df(test_newgram)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# display(test_ngram_df)\n",
    "\n",
    "fig = px.line(test_ngram_df, x=\"date\", y=\"percentage\", color=\"country\", title=f'Ngram: \"{test_term}\"')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c983b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "test_term = \"democratie\"\n",
    "\n",
    "test_newgram = {\"content_simplified\":test_term, \"year\":\"2018\"}\n",
    "\n",
    "test_ngram_df = get_ngram_df(test_newgram, \"months\")\n",
    "\n",
    "# display(test_ngram_df)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "fig = px.line(test_ngram_df, x=\"date\", y=\"percentage\", color=\"country\", title=f'Ngram: \"{test_term}\"')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ca103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "test_term = \"democratie\"\n",
    "\n",
    "test_newgram = {\"content_simplified\":test_term, \"year\":\"2018\", \"month\":\"07\"}\n",
    "\n",
    "test_ngram_df = get_ngram_df(test_newgram, \"days\")\n",
    "\n",
    "# display(test_ngram_df)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "fig = px.line(test_ngram_df, x=\"date\", y=\"percentage\", color=\"country\", title=f'Ngram: \"{test_term}\"')\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
